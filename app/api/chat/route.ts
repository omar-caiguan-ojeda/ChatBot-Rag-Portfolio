import { streamText, UIMessage, convertToModelMessages } from 'ai';
import { getCVRAGContext } from '@/lib/cv-embeddings';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

// Type guard to check for text/content properties in message parts
function isPartWithText(part: unknown): part is { text: string } | { content: string } {
  return (
    typeof part === 'object' &&
    part !== null &&
    ('text' in part || 'content' in part)
  );
}

function extractTextFromMessage(message: UIMessage): string {
  const content = (message as { content?: unknown }).content;
  const parts = (message as { parts?: unknown }).parts;

  const extractFromParts = (items: unknown[]): string => {
    return items
      .map(part => {
        if (typeof part === 'string') return part;
        if (isPartWithText(part)) {
          return (part as { text?: string }).text || (part as { content?: string }).content || '';
        }
        return '';
      })
      .join(' ');
  };

  if (Array.isArray(parts)) {
    return extractFromParts(parts);
  }

  if (typeof content === 'string') {
    return content;
  }

  if (Array.isArray(content)) {
    return extractFromParts(content);
  }

  return '';
}

export async function POST(req: Request) {
  const {
    messages,
    model,
    webSearch,
    useRAG = true,
  }: { 
    messages: UIMessage[]; 
    model: string; 
    webSearch: boolean;
    useRAG?: boolean;
  } = await req.json();

  // Obtener el √∫ltimo mensaje del usuario para b√∫squeda RAG
  const lastMessage = messages[messages.length - 1];
  let ragContext = '';

  // Debug: log all messages structure
  console.log('üìã Total messages:', messages.length);
  console.log('üìã Last message:', JSON.stringify(lastMessage, null, 2));

  // Si RAG est√° habilitado y no es b√∫squeda web, obtener contexto del CV
  if (useRAG && !webSearch && lastMessage?.role === 'user') {
    const messageContent = extractTextFromMessage(lastMessage);
    console.log('üîç RAG activado, procesando mensaje:', messageContent);

    //console.log('üîç RAG activado, procesando mensaje:', lastMessage.content);
    try {
      // Extract text content from UIMessage - handle multiple formats
      console.log('üìù Contenido extra√≠do:', messageContent);
      
      if (messageContent && messageContent.trim()) {
        console.log('üöÄ Llamando a getCVRAGContext...');
        ragContext = await getCVRAGContext(messageContent.trim());
        console.log('‚úÖ Contexto RAG obtenido:', ragContext ? `${ragContext.length} caracteres` : 'vac√≠o');
      } else {
        console.log('‚ö†Ô∏è No se pudo extraer contenido del mensaje');
      }
    } catch (error) {
      console.error('‚ùå Error getting CV RAG context:', error);
    }
  } else {
    console.log('‚ö†Ô∏è RAG no activado. useRAG:', useRAG, 'webSearch:', webSearch, 'lastMessage role:', lastMessage?.role);
  }

  // Define el prompt base que siempre se usar√°
  let systemPrompt = `**Tu Rol y Objetivo:**
Eres un asistente de IA conversacional que representa a Omar Caiguan, un Programador Web Profesional. Tu nombre es "Asistente de IA de Omar".

**Tu Persona:**
Tu prop√≥sito es ayudar a los usuarios a conocer la experiencia profesional, proyectos y habilidades de Omar. Responde de manera profesional, amigable y servicial. Cuando te pregunten qui√©n eres, pres√©ntate como el asistente de IA de Omar. No finjas ser Omar, sino que hablas en su nombre.

**Reglas Cr√≠ticas de Respuesta:**
1. **Identidad Clara:** Si te preguntan "¬øqui√©n eres?" o "a qui√©n representas?", responde: "Soy el asistente de inteligencia artificial de Omar Caiguan, creado para responder preguntas sobre su carrera profesional".
2. **Fuente de Conocimiento:** 
   - Siempre que respondas bas√°ndote en el CV de Omar, incluye al final: "[Fuente: CV Omar Caiguan]"
   - Si la respuesta no est√° en el CV, di claramente: "No tengo esa informaci√≥n espec√≠fica en el CV de Omar, pero puedo contarte sobre sus habilidades y experiencia profesional."
3. **Transparencia:** Si alguien pregunta c√≥mo obtienes la informaci√≥n, explica que usas un sistema de b√∫squeda en la base de datos del CV de Omar para proporcionar respuestas precisas.`;

  // Si se encontr√≥ contexto RAG, se a√±ade al prompt del sistema
  if (ragContext) {
    systemPrompt += `

**Contexto T√©cnico (Base de Conocimiento del CV de Omar):**
La siguiente informaci√≥n ha sido extra√≠da del CV y portafolio de Omar para responder tu pregunta. √ösala como tu principal fuente de verdad.
---
${ragContext}
---`;
  } else {
    systemPrompt += `

**Nota:** No se encontr√≥ informaci√≥n espec√≠fica en el CV para responder a preguntas detalladas. Por favor, haz preguntas generales sobre la experiencia y habilidades de Omar.`;
  }

  // Debug logging
  console.log('üîç SystemPrompt completo:')
  console.log('='.repeat(50))
  console.log(systemPrompt)
  console.log('='.repeat(50))
  console.log(`üìè Longitud del systemPrompt: ${systemPrompt.length} caracteres`)

  const result = streamText({
    model: webSearch ? 'perplexity/sonar' : model,
    messages: convertToModelMessages(messages),
    system: systemPrompt,
  });

  // send sources and reasoning back to the client
  return result.toUIMessageStreamResponse({
    sendSources: true,
    sendReasoning: true,
  });
}