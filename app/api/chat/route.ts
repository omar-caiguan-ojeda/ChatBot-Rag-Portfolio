import { streamText, UIMessage, convertToModelMessages } from 'ai';
import { getCVRAGContext } from '@/lib/cv-embeddings';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

export async function POST(req: Request) {
  const {
    messages,
    model,
    webSearch,
    useRAG = true,
  }: { 
    messages: UIMessage[]; 
    model: string; 
    webSearch: boolean;
    useRAG?: boolean;
  } = await req.json();

  // Obtener el √∫ltimo mensaje del usuario para b√∫squeda RAG
  const lastMessage = messages[messages.length - 1];
  let ragContext = '';

  // Debug: log all messages structure
  console.log('üìã Total messages:', messages.length);
  console.log('üìã Last message:', JSON.stringify(lastMessage, null, 2));

  // Si RAG est√° habilitado y no es b√∫squeda web, obtener contexto del CV
  if (useRAG && !webSearch && lastMessage?.role === 'user') {
    const messageContent = lastMessage.parts
        ? lastMessage.parts.map((part: any) => part.text).join(' ')
        : '';
    console.log('üîç RAG activado, procesando mensaje:', messageContent);

    //console.log('üîç RAG activado, procesando mensaje:', lastMessage.content);
    try {
      // Extract text content from UIMessage - handle multiple formats
      let messageContent = '';
      
      // Check for parts array format (AI SDK v5)
      if ((lastMessage as any).parts && Array.isArray((lastMessage as any).parts)) {
        messageContent = (lastMessage as any).parts
          .filter((part: any) => part.type === 'text')
          .map((part: any) => part.text)
          .join(' ');
      }
      // Try different ways to extract content
      // else if (typeof lastMessage.content === 'string') {
      //   messageContent = lastMessage.content;
      // } else if (Array.isArray(lastMessage.content)) {
      //   messageContent = lastMessage.content
      //     .map(part => {
      //       if (typeof part === 'string') return part;
      //       if (typeof part === 'object' && part !== null) {
      //         return (part as any).text || (part as any).content || '';
      //       }
      //       return '';
      //     })
      //     .filter(Boolean)
      //     .join(' ');

      // } else if (lastMessage.content && typeof lastMessage.content === 'object') {
      //   // Handle object format
      //   messageContent = (lastMessage.content as any).text || (lastMessage.content as any).content || '';
      // }

      // else if (typeof ((lastMessage as any).content)) {
      //   messageContent = (lastMessage as any).content;
      // } else if (Array.isArray((lastMessage as any).content)) {
      //   messageContent = (lastMessage as any).content
      //     .map(part => {
      //       if (typeof part === 'string') return part;
      //       if (typeof part === 'object' && part !== null) {
      //         return (part as any).text || (part as any).content || '';
      //       }
      //       return '';
      //     })
      //     .filter(Boolean)
      //     .join(' ');

      else if (Array.isArray((lastMessage as any).content)) {
        messageContent = (lastMessage as any).content
          .map((part: any) => {
            if (typeof part === 'string') return part;
            if (typeof part === 'object' && part !== null) {
              return (part as any).text || (part as any).content || '';
            }
            return '';
          })
          .filter(Boolean)
          .join(' ');

      } else if ((lastMessage as any).content && typeof (lastMessage as any).content === 'object') {
        // Handle object format
        messageContent = (lastMessage as any).content.text || (lastMessage as any).content.content || '';
      }
      
      // Fallback: try to get text from other message properties
      if (!messageContent && (lastMessage as any).text) {
        messageContent = (lastMessage as any).text;
      }
      
      // // Last resort: stringify and extract if it's a complex object
      // if (!messageContent && lastMessage.content) {
      //   try {
      //     const contentStr = JSON.stringify(lastMessage.content);
      //     if (contentStr && contentStr !== '{}' && contentStr !== 'null') {
      //       messageContent = contentStr;
      //     }
      //   } catch (e) {
      //     // Ignore JSON errors
      //   }
      // }
      if (!messageContent && (lastMessage as any).text) {
        messageContent = (lastMessage as any).text;
      }

      // Last resort: convertir a string si es un objeto complejo
      if (!messageContent && (lastMessage as any).content) {
        try {
          const contentStr = JSON.stringify((lastMessage as any).content);
          if (contentStr && contentStr !== '{}' && contentStr !== 'null') {
            messageContent = contentStr;
          }
        } catch (e) {
          // Ignorar errores de JSON
        }
      }
      
      console.log('üìù Contenido extra√≠do:', messageContent);
      
      if (messageContent && messageContent.trim()) {
        console.log('üöÄ Llamando a getCVRAGContext...');
        ragContext = await getCVRAGContext(messageContent.trim());
        console.log('‚úÖ Contexto RAG obtenido:', ragContext ? `${ragContext.length} caracteres` : 'vac√≠o');
      } else {
        console.log('‚ö†Ô∏è No se pudo extraer contenido del mensaje');
      }
    } catch (error) {
      console.error('‚ùå Error getting CV RAG context:', error);
    }
  } else {
    console.log('‚ö†Ô∏è RAG no activado. useRAG:', useRAG, 'webSearch:', webSearch, 'lastMessage role:', lastMessage?.role);
  }

  // Construir prompt del sistema con contexto del CV
  let systemPrompt = 'Eres un asistente √∫til que puede responder preguntas y ayudar con tareas';
  
  if (ragContext) {
    systemPrompt = `**Tu Rol y Objetivo:**
Eres un asistente de IA de √©lite que representa a Omar Leonardo Caiguan Ojeda, un Programador Web Profesional con amplia experiencia. Tu objetivo principal es responder preguntas sobre su perfil, proyectos y habilidades de manera precisa, profesional y convincente, bas√°ndote *√∫nica y exclusivamente* en el contexto proporcionado.

**Tu Persona:**
Act√∫a como si fueras Omar. Utiliza la primera persona ("Yo", "mi", "desarroll√©"). Proyecta confianza, competencia t√©cnica y pasi√≥n por el desarrollo de software. Tu tono debe ser profesional pero accesible.

**Contexto T√©cnico (Tu Base de Conocimiento):**
A continuaci√≥n se encuentra la informaci√≥n extra√≠da directamente del CV y portafolio de Omar. Esta es tu √∫nica fuente de verdad.
---
${ragContext}
---

**Reglas Cr√≠ticas de Respuesta:**

1.  **Exclusividad del Contexto:** NUNCA utilices conocimiento externo a la informaci√≥n proporcionada arriba. Si la respuesta no est√° en el contexto, es crucial que no inventes nada.
2.  **Formato Profesional:** Estructura tus respuestas para m√°xima claridad. Utiliza markdown (listas, negritas) para resaltar tecnolog√≠as, proyectos o habilidades clave. Por ejemplo: "Para el backend, utilic√© **Node.js** y **Express**, con una base de datos **PostgreSQL**."
3.  **Respuesta Directa y Concisa:** Ve al grano. Responde la pregunta del usuario de forma directa y evita informaci√≥n superflua.
4.  **Manejo de Informaci√≥n Faltante:** Si la respuesta no se encuentra en el contexto, responde con una de las siguientes frases de manera profesional:
    *   "No tengo detalles espec√≠ficos sobre ese punto en la informaci√≥n de mi perfil, pero puedo contarte sobre..." (y ofreces un tema relacionado que s√≠ est√© en el contexto).
    *   "Esa informaci√≥n no est√° incluida en mi CV. ¬øTe gustar√≠a que profundice en alguno de mis proyectos o habilidades?"
5.  **S√≠ntesis, no copia:** No copies y pegues el contexto. Sintetiza la informaci√≥n relevante para construir una respuesta natural y coherente.

Ahora, bas√°ndote en todas estas reglas, responde la pregunta del usuario.`
  }

  // Debug logging
  console.log('üîç SystemPrompt completo:')
  console.log('='.repeat(50))
  console.log(systemPrompt)
  console.log('='.repeat(50))
  console.log(`üìè Longitud del systemPrompt: ${systemPrompt.length} caracteres`)

  const result = streamText({
    model: webSearch ? 'perplexity/sonar' : model,
    messages: convertToModelMessages(messages),
    system: systemPrompt,
  });

  // send sources and reasoning back to the client
  return result.toUIMessageStreamResponse({
    sendSources: true,
    sendReasoning: true,
  });
}